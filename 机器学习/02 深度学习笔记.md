# 深度神经网络
参考课程：[A Single Neuron | Kaggle](https://www.kaggle.com/code/ryanholbrook/a-single-neuron)
[Deep Learning Tutorial](https://www.geeksforgeeks.org/deep-learning/deep-learning-tutorial/)


深度学习通过从大数据集中学习、并且应用多层神经网络，自动发现模式并且用于预测，这消除了feature工程。

* The Linear Unit：神经网络基础、神经元

* activation function: **activation function** is simply some function we apply to each of a layer's outputs (its *activations*).

* When we attach the rectifier to a linear unit, we get a **rectified linear unit** or **ReLU**

* 隐藏层：在输出前的层都叫隐藏层。

* A "loss function" that measures how good the network's predictions are.

* An "optimizer" that can tell the network how to change its weights.

* *Stochastic gradient descent* ：随机梯度下降；随机梯度下降法

## 深度神经网络的类型

### 卷积神经网络：CNN（Convolutional Neural Networks）

### 循环神经网络：RNN (Recurrent Neural Networks)

### Generative Models in Deep Learning

### Deep Reinforcement Learning (DRL)



# Deep Learning Models类型（主要神经网络类型）
1. ANNs
2. CNNs
3. RNNs
4. FNNs（Feedforward neural networks）
5. LSTMs（Long Short Term Memory Networks）
6. Generative Adversarial Networks（GANs）
* Autoencoders，Transformer Networks
* Singlelayer Perceptron
* Multilayer Perceptron(MLP)

# 应用
1. 自动驾驶、
2. 医疗诊断
3. 语音识别、
4. 人脸识别、
5. 推荐系统、
6. Fraud Detection

# 挑战
1. 需要大数据集、
2. 高性能硬件、
3. 训练数据过拟合的分享、
4. 缺少透明和解释性




## ANN（Artificial Neural Networks）

单个神经元 A single neuron，也叫感知器（perceptron）、
构成：
* Input
* Weights + Biases
* Activation functions：更多见下文介绍。
* Loss Functions

* Gradient Descent：梯度下降法



### 神经网络主要有下面这些组件：
These networks are built from several key components:

* Neurons: The basic units that receive inputs, each neuron is governed by a threshold and an activation function.
* Connections: Links between neurons that carry information, regulated by weights and biases.
* Weights and Biases: These parameters determine the strength and influence of connections.
* Propagation Functions: Mechanisms that help process and transfer data across layers of neurons.
* Learning Rule: The method that adjusts weights and biases over time to improve accuracy.

### 神经网络的工作原理
1. Activation：激活函数： 

 The activation function is crucial because it introduces non-linearity into the system, enabling the network to learn more complex patterns. Popular activation functions include ReLU, sigmoid and tanh.

如果没有激活函数，那么就只能是在线形空间变换了，所以激活函数很重要。

激活函数：常见的激活函数有Tanh activation function、也有sigmoid function等等。

In image, there is a tanh function that is unknown for you. It is a activation function like sigmoid function. Tanh activation function is better than sigmoid for hidden units bacause mean of its output is closer to zero so it centers the data better for the next layer. Also tanh activation function increase non linearity that cause our model learning better.

2. Forward Progagation： 正向传递

    神经网络中数据从输入层通过计算，一层一层传递下去，最终得到输出并且计算损失函数的过程。叫正向传播。

    a. Linear Tranformation： 进行线性变化、

3. Back propagation 反向传播
    反向传播是反向传播计算更新优化参数的过程。通过链式求偏导计算，然后比较结果值和目标值的差异，使得目标值越来越小。最终得到最优化的参数。

a. Loss Calculation: 损失函数 评估模型效果、然后反向推动前面的参数变化
b. Gradient Calculation：梯度下降、 
c. Weight Update: 更新权重
    using an optimization algorithm like stochastic gradient descent (SGD).

4. Iteration

5. 优化器：optimizer

常见的隐层和激活函数的选择：
* relu等：
* sigmoid等

# 卷积神经网络：CNN

1. 卷积神经网络：通过卷积层、自动检测边界、纹理、形状等模式，特别适合图像识别。

2. 为什么需要它？
在全连接神经网络处理图像时，会遇到几个致命问题：
* a. 参数爆炸：一张100x100x3的彩色图片，输入层就有3万个节点。如果第一个隐藏层有1000个神经元，那么仅这一层就有 3000万个权重参数！训练这样的网络几乎是不可能的。
* b. 平移不变性：全连接网络很难理解“一只猫无论出现在图片的左上角还是右下角，它都是猫”这个概念。它学习到的是像素在特定位置的特征。
* c. 空间局部相关性：图像中有价值的特征（如边缘、角点、纹理）通常都是由局部相邻的像素决定的。全连接网络会平等地看待相距很远和很近的像素，这不符合图像的固有特性。

3. 核心思想：卷积层通过局部连接和权值共享巧妙地解决了上述问题。
* 局部连接：每个神经元只与前一层的一小块区域（局部感受野）连接。
* 权值共享：同一个卷积核（滤波器）会滑过整个图像。这意味着无论猫的眼睛出现在哪里，都由同一个“眼睛探测器”来识别，这天然赋予了网络平移不变性的能力，同时极大地减少了参数数量。

## 卷积层

卷积层是：你的“边缘和图案探测器”。它先找到眼睛的轮廓、胡须的线条等局部特征。


## 池化层

1. 局部感受野
池化操作在输入特征图的局部区域（如2×2、3×3）上进行，每个池化窗口就是一个局部感受野。

2. 统计函数
对每个局部感受野应用一个统计函数，最常见的是：

* 最大值函数（最大池化）
* 平均值函数（平均池化）

3. 池化层的计算过程
基本参数
池化窗口大小：如 2×2, 3×3

步长：窗口每次移动的像素数
填充：通常在池化中很少使用填充



池化层主要是对kernal内的多个数据取最大值（最大池化）、或者平均值（平均池化）。
池化层的计算和数学原理，参考ex_max_pool.ipynb.

你的“抽象概括器”。它告诉你“在图片的左上角区域有一个眼睛的图案”，而不关心这个眼睛精确到每一个像素在哪。这让你对位置变化不敏感。

为什么需要它？
1. **平移、旋转、缩放的不变性**：即使猫的图像稍微移动了几个像素，或者有轻微的旋转，池化（尤其是最大池化）后的输出基本保持不变。这使得网络对微小的形变不敏感，更具鲁棒性。
2. **降维与防止过拟合**：池化操作（如2x2池化，步长为2）会将特征图的尺寸减小到原来的一半，从而显著减少后续层的参数和计算量。参数少了，过拟合的风险自然就降低了。
3. **扩大感受野：通过池化**，后续的卷积层能“看到”前一层特征图中更广的区域，从而整合更大范围的信息。



## Dropout层
Dropout层：你的“防过拟合训练法”。就像在备考时，你不能只死记硬背例题，而要理解概念。它通过随机“忘记”一些信息，强迫网络学习更鲁棒的特征。

* 为什么需要它？
核心问题：过拟合。当网络复杂（参数多）而训练数据不足时，网络会倾向于“死记硬背”训练数据，包括其中的噪声和不重要的细节，导致在训练集上表现完美，但在未见过的测试集上表现很差。


## 展品层

## 全连接层

## 

## 思考： 设计模型的时候应该怎么抉择选择设计多少层卷积层、多少层池化层？



# 前馈神经网络
1. 人工神经网络和卷积神经网络，可以称为前馈神经网络。每个神经元只与前一层的神经元相连，接收前一层的输出、并输出给下一层，各层间没有反馈。每一层内部的神经元之间也没有任何反馈机制。

# 循环神经网络：RNN（Recurrent Neural Networks）
适合具有先后关系的序列，比如基于的时间关系的序列、文本等，如NLP。

## 参见RNN类型：
1. SimpleRNN
2. LSTM：Long Short-Term Memory 长短记忆网络
3. GRUs 门循环但愿

* RNN 的核心思想
RNN 的核心在于循环连接（Recurrent Connection），即网络的输出不仅取决于当前输入，还取决于之前所有时间步的输入。这种结构使 RNN 能够处理任意长度的序列数据。

传统神经网络：输入和输出是独立的（例如图像分类，单张图片之间无关联）。
RNN：通过循环连接（Recurrent Connection）将上一步的隐藏状态传递到下一步，形成"记忆"。

每一步的输入 = 当前数据 + 上一步的隐藏状态。

输出不仅依赖当前输入，还依赖之前所有步骤的上下文。

## SimpleRNN 

介绍文档参考：https://www.runoob.com/nlp/recurrent-neural-network.html

```
# 简单的 RNN 单元实现示例
import numpy as np

class SimpleRNN:
    def __init__(self, input_size, hidden_size):
        self.Wx = np.random.randn(hidden_size, input_size)  # 输入权重
        self.Wh = np.random.randn(hidden_size, hidden_size)  # 隐藏状态权重
        self.b = np.zeros((hidden_size, 1))  # 偏置项
    
    def forward(self, x, h_prev):
        h_next = np.tanh(np.dot(self.Wx, x) + np.dot(self.Wh, h_prev) + self.b)
        return h_next
```
## LSTM
LSTM 引入了三个门控机制和一个记忆单元：
* 输入门	控制新信息的流入
* 遗忘门	决定丢弃哪些旧信息
* 输出门	控制输出的信息量
* 记忆单元	保存长期状态

LSTM 如何解决长期依赖问题
选择性记忆：遗忘门可以决定保留或丢弃特定信息
梯度通路：记忆单元提供了相对直接的梯度传播路径
信息保护：记忆内容不会被每个时间步的操作直接修改

```
# LSTM 单元的基本实现
class LSTMCell:
    def __init__(self, input_size, hidden_size):
        # 组合所有门的权重
        self.W = np.random.randn(4*hidden_size, input_size+hidden_size)
        self.b = np.random.randn(4*hidden_size, 1)
    
    def forward(self, x, h_prev, c_prev):
        combined = np.vstack((h_prev, x))
        gates = np.dot(self.W, combined) + self.b
        
        # 分割得到各个门
        f_gate = sigmoid(gates[:hidden_size])  # 遗忘门
        i_gate = sigmoid(gates[hidden_size:2*hidden_size])  # 输入门
        o_gate = sigmoid(gates[2*hidden_size:3*hidden_size])  # 输出门
        c_candidate = np.tanh(gates[3*hidden_size:])  # 候选记忆
        
        # 更新记忆和隐藏状态
        c_next = f_gate * c_prev + i_gate * c_candidate
        h_next = o_gate * np.tanh(c_next)
        
        return h_next, c_next

```
## 门控循环单元（GRU）
GRU（Gated Recurrent Unit）是 LSTM 的简化版本，在保持相似性能的同时减少了参数数量。

* GRU 的核心结构
GRU 合并了 LSTM 的某些组件：

组件	功能
* 更新门	决定保留多少旧信息
* 重置门	决定如何组合新旧信息
* 候选激活	基于重置门计算的新状态


## RNN的类型
1. One-to-One RNN
2. One-to-Many RNN
3. Many-to-One RNN
4. Many-to-Many RNN



# Reinforcement learning：增强学习
增强学习通过获取周围环境的反馈，然后应用优化策略和决策、并迭代优化。主要应用于游戏、决策制定等场景。

A branch of machine learning called reinforcement learning focuses on teaching agents to make particular choices using their experiences in a dynamic environment. 

The basic components of reinforcement learning include:

* Agent: The learner or decision-maker that interacts with the environment. It takes actions based on the information it receives and the policy it follows.

* Environment: The external system with which the agent interacts. It provides feedback to the agent in the form of rewards and influences the state of the environment.

* Actions: Choices that the agent can make. These actions are usually determined by a policy, which is the strategy that the agent employs to determine its behavior.

* State: The current situation that the agent finds itself in within the environment. The state provides context for the agent to make decisions.

* Rewards: Feedback from the environment that the agent seeks to maximize over time. Rewards are used to reinforce or discourage certain behaviors.






## 实践问题

1. ModuleNotFoundError: No module named 'sklearn'

```python
pip3 install scikit-learn 
```
