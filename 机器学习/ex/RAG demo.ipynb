{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5083402-96f8-419d-a849-4593d1777b8f",
   "metadata": {},
   "source": [
    "# 实践学习使用LangChain构建RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9b191b-3924-4b50-ab8b-a95edf8b64cf",
   "metadata": {},
   "source": [
    "实践RAG\n",
    "需要预先安装下列模块\n",
    "\n",
    "```\n",
    "# 环境准备，安装相关依赖\n",
    "!pip install langchain sentence_transformers chromadb\n",
    "\n",
    "!pip install -U langchain-community\n",
    "!pip install pypdf\n",
    "!pip install -U langchain-huggingface\n",
    "!pip install -qU langchain-ollama\n",
    "\n",
    "安装Ollama、\n",
    "ollama pull llama3\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfd990a6-034a-436e-9d23-bfc0980b7568",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./data/What I Worked on.txt\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f218bae5-c0e6-42aa-997f-807f5298b781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 508, which is longer than the specified 500\n",
      "Created a chunk of size 777, which is longer than the specified 500\n",
      "Created a chunk of size 557, which is longer than the specified 500\n",
      "Created a chunk of size 587, which is longer than the specified 500\n",
      "Created a chunk of size 622, which is longer than the specified 500\n",
      "Created a chunk of size 775, which is longer than the specified 500\n",
      "Created a chunk of size 604, which is longer than the specified 500\n",
      "Created a chunk of size 618, which is longer than the specified 500\n",
      "Created a chunk of size 520, which is longer than the specified 500\n",
      "Created a chunk of size 602, which is longer than the specified 500\n",
      "Created a chunk of size 1004, which is longer than the specified 500\n",
      "Created a chunk of size 1203, which is longer than the specified 500\n",
      "Created a chunk of size 844, which is longer than the specified 500\n",
      "Created a chunk of size 910, which is longer than the specified 500\n",
      "Created a chunk of size 674, which is longer than the specified 500\n",
      "Created a chunk of size 814, which is longer than the specified 500\n",
      "Created a chunk of size 530, which is longer than the specified 500\n",
      "Created a chunk of size 603, which is longer than the specified 500\n",
      "Created a chunk of size 772, which is longer than the specified 500\n",
      "Created a chunk of size 571, which is longer than the specified 500\n",
      "Created a chunk of size 594, which is longer than the specified 500\n",
      "Created a chunk of size 628, which is longer than the specified 500\n",
      "Created a chunk of size 689, which is longer than the specified 500\n",
      "Created a chunk of size 641, which is longer than the specified 500\n",
      "Created a chunk of size 585, which is longer than the specified 500\n",
      "Created a chunk of size 764, which is longer than the specified 500\n",
      "Created a chunk of size 502, which is longer than the specified 500\n",
      "Created a chunk of size 640, which is longer than the specified 500\n",
      "Created a chunk of size 507, which is longer than the specified 500\n",
      "Created a chunk of size 564, which is longer than the specified 500\n",
      "Created a chunk of size 707, which is longer than the specified 500\n",
      "Created a chunk of size 615, which is longer than the specified 500\n",
      "Created a chunk of size 733, which is longer than the specified 500\n",
      "Created a chunk of size 625, which is longer than the specified 500\n",
      "Created a chunk of size 576, which is longer than the specified 500\n",
      "Created a chunk of size 534, which is longer than the specified 500\n",
      "Created a chunk of size 528, which is longer than the specified 500\n",
      "Created a chunk of size 565, which is longer than the specified 500\n",
      "Created a chunk of size 552, which is longer than the specified 500\n",
      "Created a chunk of size 596, which is longer than the specified 500\n",
      "Created a chunk of size 1025, which is longer than the specified 500\n",
      "Created a chunk of size 900, which is longer than the specified 500\n",
      "Created a chunk of size 614, which is longer than the specified 500\n",
      "Created a chunk of size 635, which is longer than the specified 500\n",
      "Created a chunk of size 549, which is longer than the specified 500\n",
      "Created a chunk of size 644, which is longer than the specified 500\n",
      "Created a chunk of size 551, which is longer than the specified 500\n",
      "Created a chunk of size 527, which is longer than the specified 500\n",
      "Created a chunk of size 563, which is longer than the specified 500\n",
      "Created a chunk of size 511, which is longer than the specified 500\n",
      "Created a chunk of size 634, which is longer than the specified 500\n",
      "Created a chunk of size 611, which is longer than the specified 500\n",
      "Created a chunk of size 526, which is longer than the specified 500\n",
      "Created a chunk of size 637, which is longer than the specified 500\n",
      "Created a chunk of size 591, which is longer than the specified 500\n",
      "Created a chunk of size 543, which is longer than the specified 500\n",
      "Created a chunk of size 758, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    "# 文档分割\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# 创建拆分器\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=10)\n",
    "# 拆分文档\n",
    "documents = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c1eac3f-fa8f-4057-97ae-12b19e6b2ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasonye/python_env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 向量化\n",
    "\n",
    "# from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# embedding model: m3e-base\n",
    "model_name = \"moka-ai/m3e-base\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17e077a9-1221-465c-aa62-ec65160e3797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据入库\n",
    "\n",
    "# 指定 persist_directory 将会把嵌入存储到磁盘上。\n",
    "persist_directory = 'db'\n",
    "db = Chroma.from_documents(documents, embedding, persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e0ddf1f-a6a9-42c2-b200-cebc2ce49a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检索\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03fdee90-8e04-4e16-98a0-7355c5931354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增强\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a95f433-9fcc-40c8-93e8-9188c884de2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author applied to RISD (Rhode Island School of Design) in the fall of 1992. There is no mention of Accademia or any other art school being considered as a separate application, but rather it's mentioned that the Accademia was a \"joke\" previously, suggesting that it may have been an initial consideration that didn't pan out.\n"
     ]
    }
   ],
   "source": [
    "# 生成结果\n",
    "# pip install -U langchain-ollama\n",
    "from langchain_ollama import ChatOllama\n",
    "# from langchain_community.chat_models import ChatOllama\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "llm = ChatOllama(model='llama3')\n",
    "\n",
    "rag_chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "query = \"What did the author do growing up?\"\n",
    "query = \"Who is the author?\"\n",
    "query = \"Which art schools did the author apply?\"\n",
    "response = rag_chain.invoke(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e9d655-636e-4fa1-95f3-92f731c73c73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
